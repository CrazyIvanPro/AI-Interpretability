# Papers

[1] **Leveraging Sparse Linear Layers for Debuggable Deep Networks** 
	
    最后一层的线性层用于可解释性！
    
    https://arxiv.org/pdf/2105.04857.pdf

[2] **Connecting Interpretability and Robustness in Decision Trees through Separation**
	
    决策树中的鲁棒性与可解释性的关系
    
    https://arxiv.org/pdf/2102.07048.pdf

[3] On the price of explainability for some clustering problems
	
    为了可解释性， k-means等算法需要有牺牲

[4] On Explainability of Graph Neural Networks via Subgraph Explorations
	
    使用subgraph 做可解释性

[5] **Towards the Unification and Robustness of Perturbation and Gradient Based Explanations**
	
    LIME的理论解释，gradient based，最后会收敛到同一个地方。
    
    https://arxiv.org/pdf/2102.10618.pdf

[6] What does LIME really see in images?
	
    LIME的理论解释，gradient based，最后会收敛到同一个地方。

[7] **GANMEX: One-vs-One Attributions using GAN-based Model Explainability**
	
    用 nearestneighbor one vs one 的方式解释

[8] A Framework to Learn with Interpretation
	
    边学边有可解释性

[9] Scalable rule-based representation learning for interpretable classification

    用gd train decision tree

[10] Neural additive models: interpretable machine learning with neural nets
	
    在NN上面套一层线性层，用来给解释性

[11] Reliable post hoc explanations: modeling uncertainty in explainability
	
    Bayesian版本的可解释性

[12] **Explaining latent representations with a corpus of examples**
	
    使用例子解释
    
    https://arxiv.org/pdf/2110.15355.pdf

[13] **Refining language models with compositional explanations**
	
    复合解释，挺有意思的
    
    https://arxiv.org/abs/2103.10415.pdf

[14] One explanation is not enough: structured attention graphs for image classification
	
    用复合的attention解释答案

[15] Provable efficient, succinct and precise explanations
	
    理论角度从决策树进行分析

[16] **The out-of-distribution problem in explainability and search methods for feature importance explanations.**

	Ood 与feature importance
	
	https://arxiv.org/abs/2106.00786.pdf

[17] **Explanations-based data augmentation for image classification**
	
    对数据集进行了修改，改善了可解释性
    
    https://papers.nips.cc/paper/2021/file/af3b6a54e9e9338abc54258e3406e485-Paper.pdf

[18] **Interactive label cleaning with example-based explanations.**
	
    从数据集入手，找到有问题的数据可以重新标注
    
    https://arxiv.org/pdf/2106.03922.pdf

[19] Fine-grained neural network explanation by identifying input features with predictive information
	
    Feature attribution问题

[20] Shapley residuals: quantifying the limits of the shapley value for explanations
	
    Shapley residual是一种计算feature 额外importance的方法

[21] Brittle interpretations: The Vulnerability of TCAV and Other Concept-based Explainability Tools to Adversarial Attack
	
    就算是可解释性，也容易被adv攻击

[22] Robust Models Are More Interpretable Because Attributions Look Normal
	
    Robust model -> 更加光滑 -> 更加容易解释

[23] Explanations of Black-Box Models based on Directional Feature Interactions
	
    根据feature interaction给出解释

[24] Cartoon Explanations of Image Classifiers
	
    Image 里面的稀疏解释

[25] NIPS 2021 - EDDA: Explanation driven Data Augmentation to Improve Explanation Faithfulness

    https://arxiv.org/abs/2105.14162.pdf

[26] KDD 2016 - "Why Should I Trust You?" Explaining the Predictions of Any Classifier

	LIME - Local Interpretable Model-agnostic Explanations
	
	https://arxiv.org/pdf/1602.04938.pdf